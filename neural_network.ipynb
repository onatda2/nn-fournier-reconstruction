{"cells":[{"cell_type":"markdown","source":["# Assignment 2\n","\n","In this assignment you will create a coordinate-based multilayer perceptron in numpy from scratch. For each input image coordinate $(x,y)$, the model predicts the associated color $(r,g,b)$.\n","\n","![Network diagram](https://user-images.githubusercontent.com/3310961/85066930-ad444580-b164-11ea-9cc0-17494679e71f.png)\n","\n","You will then compare the following input feature mappings $\\gamma (\\mathbf{v})$.\n","\n","- No mapping: $\\gamma(\\mathbf{v})= \\mathbf{v}$. \n","\n","- Basic mapping: $\\gamma(\\mathbf{v})=\\left[ \\cos(2 \\pi \\mathbf{v}),\\sin(2 \\pi \\mathbf{v}) \\right]^\\mathrm{T}$. \n","\n","- Gaussian Fourier feature mapping: $\\gamma(\\mathbf{v})= \\left[ \\cos(2 \\pi \\mathbf B \\mathbf{v}), \\sin(2 \\pi \\mathbf B \\mathbf{v}) \\right]^\\mathrm{T}$, \n","where each entry in $\\mathbf B \\in \\mathbb R^{m \\times d}$ is sampled from $\\mathcal N(0,\\sigma^2)$.\n","\n","Some notes to help you with that:\n","\n","- You will implement the mappings in the helper functions `get_B_dict` and `input_mapping`. \n","- The basic mapping can be considered a case where $\\mathbf B \\in \\mathbb R^{2 \\times 2}$ is the indentity matrix. \n","- For this assignment, $d$ is 2 because the input coordinates in two dimensions. \n","- You can experiment with $m$ and $\\sigma$ values e.g. $m=256$ and $\\sigma \\in \\{1, 10, 100\\}$.\n","\n","Source: https://bmild.github.io/fourfeat/ \n","This assignment is inspired by and built off of the authors' demo. "],"metadata":{"id":"O452YP5gcoTh"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"g1PrabcYcszP"}},{"cell_type":"markdown","source":["### (Optional) Colab Setup\n","If you aren't using Colab, you can delete the following code cell. Replace the path below with the path in your Google Drive to the uploaded assignment folder. Mounting to Google Drive will allow you access the other .py files in the assignment folder and save outputs to this folder"],"metadata":{"id":"wILGPb5Ccuxm"}},{"cell_type":"code","source":["# you will be prompted with a window asking to grant permissions\n","# click connect to google drive, choose your account, and click allow\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"id":"qd7bYYf9cl-0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: fill in the path in your Google Drive in the string below\n","# Note: do not escape slashes or spaces in the path string\n","import os\n","datadir = \"/content/assignment2\"\n","if not os.path.exists(datadir):\n","  !ln -s \"/content/drive/My Drive/path/to/your/assignment2/\" $datadir\n","os.chdir(datadir)\n","!pwd"],"metadata":{"id":"Rkf-pZcSdUjU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"EfPlwYF07wB_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5CKY4Fdna2Y-"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","import os, imageio\n","import cv2\n","import numpy as np\n","\n","# imports /content/assignment2/models/neural_net.py if you mounted correctly \n","from models.neural_net import NeuralNetwork\n","\n","# makes sure your NeuralNetwork updates as you make changes to the .py file\n","%load_ext autoreload\n","%autoreload 2\n","\n","# sets default size of plots\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0)  "]},{"cell_type":"markdown","source":["## Helper Functions"],"metadata":{"id":"MhqQzPGU7dls"}},{"cell_type":"markdown","source":["### Experiment Runner (Fill in TODOs)"],"metadata":{"id":"jWYSuPu2mP8x"}},{"cell_type":"code","source":["def NN_experiment(X_train, y_train, X_test, y_test, input_size, num_layers,\\\n","                  hidden_size, hidden_sizes, output_size, epochs,\\\n","                  learning_rate, opt):\n","  \n","  # Initialize a new neural network model\n","  net = NeuralNetwork(input_size, hidden_sizes, output_size, num_layers, opt)\n","\n","  # Variables to store performance for each epoch\n","  train_loss = np.zeros(epochs)\n","  train_psnr = np.zeros(epochs)\n","  test_psnr = np.zeros(epochs)\n","  predicted_images = np.zeros((epochs, y_test.shape[0], y_test.shape[1]))\n","\n","  # For each epoch...\n","  for epoch in tqdm(range(epochs)):\n","    \n","      # Shuffle the dataset\n","      # TODO implement this\n","      \n","      # Training\n","      # Run the forward pass of the model to get a prediction and record the psnr\n","      # TODO implement this\n","      # Run the backward pass of the model to compute the loss, record the loss, and update the weights\n","      # TODO implement this\n","\n","      # Testing\n","      # No need to run the backward pass here, just run the forward pass to compute and record the psnr\n","      # TODO implement this\n","        \n","  return net, train_psnr, test_psnr, train_loss, predicted_images"],"metadata":{"id":"tSdrQ0QR92tt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Image Data and Feature Mappings (Fill in TODOs)"],"metadata":{"id":"F_D1y-kJ7eMk"}},{"cell_type":"code","source":["# Data loader - already done for you\n","def get_image(size=512, \\\n","              image_url='https://bmild.github.io/fourfeat/img/lion_orig.png'):\n","\n","  # Download image, take a square crop from the center  \n","  img = imageio.imread(image_url)[..., :3] / 255.\n","  c = [img.shape[0]//2, img.shape[1]//2]\n","  r = 256\n","  img = img[c[0]-r:c[0]+r, c[1]-r:c[1]+r]\n","\n","  if size != 512:\n","    img = cv2.resize(img, (size, size))\n","\n","  plt.imshow(img)\n","  plt.show()\n","\n","  # Create input pixel coordinates in the unit square\n","  coords = np.linspace(0, 1, img.shape[0], endpoint=False)\n","  x_test = np.stack(np.meshgrid(coords, coords), -1)\n","  test_data = [x_test, img]\n","  train_data = [x_test[::2, ::2], img[::2, ::2]]\n","\n","  return train_data, test_data"],"metadata":{"id":"xcvnzOICobu3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the mappings dictionary of matrix B -  you will implement this\n","def get_B_dict():\n","  B_dict = {}\n","  B_dict['none'] = None\n","  \n","  # add B matrix for basic, gauss_1.0, gauss_10.0, gauss_100.0\n","  # TODO implement this\n","\n","  return B_dict"],"metadata":{"id":"6YksepPb8Yyw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Given tensor x of input coordinates, map it using B - you will implement\n","def input_mapping(x, B):\n","  if B is None:\n","    # \"none\" mapping - just returns the original input coordinates\n","    return x\n","  else:\n","    # \"basic\" mapping and \"gauss_X\" mappings project input features using B\n","    # TODO implement this\n","    pass"],"metadata":{"id":"B_9mubvp8aY1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply the input feature mapping to the train and test data - already done for you\n","def get_input_features(B_dict, mapping):\n","  # mapping is the key to the B_dict, which has the value of B\n","  # B is then used with the function `input_mapping` to map x  \n","  y_train = train_data[1].reshape(-1, output_size)\n","  y_test = test_data[1].reshape(-1, output_size)\n","  X_train = input_mapping(train_data[0].reshape(-1, 2), B_dict[mapping])\n","  X_test = input_mapping(test_data[0].reshape(-1, 2), B_dict[mapping])\n","  return X_train, y_train, X_test, y_test"],"metadata":{"id":"UBGd4KfYjJ14"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### MSE Loss and PSNR Error (Fill in TODOs)"],"metadata":{"id":"-XZiVy05or2V"}},{"cell_type":"code","source":["def mse(y, p):\n","  # TODO implement this\n","  # make sure it is consistent with your implementation in neural_net.py\n","  pass\n","\n","def psnr(y, p):\n","  # TODO implement this\n","  pass"],"metadata":{"id":"CdJbDPL9iOer"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Plotting"],"metadata":{"id":"yeXQlG8T7ZzD"}},{"cell_type":"code","source":["def plot_training_curves(train_loss, train_psnr, test_psnr):\n","  # plot the training loss\n","  plt.subplot(2, 1, 1)\n","  plt.plot(train_loss)\n","  plt.title('MSE history')\n","  plt.xlabel('Iteration')\n","  plt.ylabel('MSE Loss')\n","\n","  # plot the training and testing psnr\n","  plt.subplot(2, 1, 2)\n","  plt.plot(train_psnr, label='train')\n","  plt.plot(test_psnr, label='test')\n","  plt.title('PSNR history')\n","  plt.xlabel('Iteration')\n","  plt.ylabel('PSNR')\n","  plt.legend()\n","\n","  plt.tight_layout()\n","  plt.show()"],"metadata":{"id":"3SniGS2aA_Ic"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_reconstruction(p, y_test):\n","  p_im = p.reshape(size,size,3)\n","  y_im = y.reshape(size,size,3)\n","\n","  plt.figure(figsize=(12,6))\n","\n","  # plot the reconstruction of the image\n","  plt.subplot(1,2,1), plt.imshow(p_im), plt.title(\"reconstruction\")\n","\n","  # plot the ground truth image\n","  plt.subplot(1,2,2), plt.imshow(y_im), plt.title(\"ground truth\")\n","\n","  print(\"Final Test MSE\", mse(y, p))\n","  print(\"Final Test psnr\",psnr(y, p))"],"metadata":{"id":"GXY0gCikFAup"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_reconstruction_progress(predicted_images, y_test, N=8):\n","  total = len(predicted_images)\n","  step = total // N\n","  plt.figure(figsize=(24, 4))\n","\n","  # plot the progress of reconstructions\n","  for i, j in enumerate(range(0,total, step)):\n","      plt.subplot(1, N, i+1)\n","      plt.imshow(predicted_images[j].reshape(size,size,3))\n","      plt.axis(\"off\")\n","      plt.title(f\"iter {j}\")\n","\n","  # plot ground truth image\n","  plt.subplot(1, N+1, N+1)\n","  plt.imshow(y.reshape(size,size,3))\n","  plt.title('GT')\n","  plt.axis(\"off\")\n","  plt.show()"],"metadata":{"id":"VcYZUf9RE-2a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_feature_mapping_comparison(outputs, gt):\n","  # plot reconstruction images for each mapping\n","  plt.figure(figsize=(24, 4))\n","  N = len(outputs)\n","  for i, k in enumerate(outputs):\n","      plt.subplot(1, N+1, i+1)\n","      plt.imshow(outputs[k]['pred_imgs'][-1].reshape(size, size, -1))\n","      plt.title(k)\n","  plt.subplot(1, N+1, N+1)\n","  plt.imshow(gt)\n","  plt.title('GT')\n","  plt.show()\n","\n","  # plot train/test error curves for each mapping\n","  iters = len(outputs[k]['train_psnrs'])\n","  plt.figure(figsize=(16, 6))\n","  plt.subplot(121)\n","  for i, k in enumerate(outputs):\n","      plt.plot(range(iters), outputs[k]['train_psnrs'], label=k)\n","  plt.title('Train error')\n","  plt.ylabel('PSNR')\n","  plt.xlabel('Training iter')\n","  plt.legend()\n","  plt.subplot(122)\n","  for i, k in enumerate(outputs):\n","      plt.plot(range(iters), outputs[k]['test_psnrs'], label=k)\n","  plt.title('Test error')\n","  plt.ylabel('PSNR')\n","  plt.xlabel('Training iter')\n","  plt.legend()\n","  plt.show()"],"metadata":{"id":"C3r5qSy3E9jy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save out video\n","def create_and_visualize_video(outputs, size=size, epochs=epochs, filename='training_convergence.mp4'):\n","  all_preds = np.concatenate([outputs[n]['pred_imgs'].reshape(epochs,size,size,3)[::25] for n in outputs], axis=-2)\n","  data8 = (255*np.clip(all_preds, 0, 1)).astype(np.uint8)\n","  f = os.path.join(filename)\n","  imageio.mimwrite(f, data8, fps=20)\n","\n","  # Display video inline\n","  from IPython.display import HTML\n","  from base64 import b64encode\n","  mp4 = open(f, 'rb').read()\n","  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","\n","  N = len(outputs)\n","  if N == 1:\n","    return HTML(f'''\n","    <video width=256 controls autoplay loop>\n","          <source src=\"{data_url}\" type=\"video/mp4\">\n","    </video>\n","    ''')\n","  else:\n","    return HTML(f'''\n","    <video width=1000 controls autoplay loop>\n","          <source src=\"{data_url}\" type=\"video/mp4\">\n","    </video>\n","    <table width=\"1000\" cellspacing=\"0\" cellpadding=\"0\">\n","      <tr>{''.join(N*[f'<td width=\"{1000//len(outputs)}\"></td>'])}</tr>\n","      <tr>{''.join(N*['<td style=\"text-align:center\">{}</td>'])}</tr>\n","    </table>\n","    '''.format(*list(outputs.keys())))"],"metadata":{"id":"k9c5MGtCE8Wf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Low Resolution Reconstruction"],"metadata":{"id":"32nZKUI87j1U"}},{"cell_type":"code","source":["size = 32\n","train_data, test_data = get_image(size)"],"metadata":{"id":"uFU-rPCFn9mN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Some suggested hyperparameter choices to help you start\n","- hidden layer count: 4\n","- hidden layer size: 256\n","- number of epochs: 1000\n","- learning reate: 1e-4\n"],"metadata":{"id":"csKDsiLaALNs"}},{"cell_type":"markdown","source":["#### Low Resolution Reconstruction - SGD - None Mapping"],"metadata":{"id":"63CMVVY9pCYy"}},{"cell_type":"code","source":["# get input features\n","# TODO implement this by using the get_B_dict() and get_input_features() helper functions\n","\n","# run NN experiment on input features\n","# TODO implement by using the NN_experiment() helper function\n","\n","# plot results of experiment\n","plot_training_curves(train_loss, train_psnr, test_psnr)\n","plot_reconstruction(net.forward(X_test), y_test)\n","plot_reconstruction_progress(predicted_images, y_test)"],"metadata":{"id":"RDcWCccppJHg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Low Resolution Reconstruction - Adam - None Mapping"],"metadata":{"id":"gleWlEqDqzhi"}},{"cell_type":"code","source":["# get input features\n","# TODO implement this by using the get_B_dict() and get_input_features() helper functions\n","\n","# run NN experiment on input features\n","# TODO implement by using the NN_experiment() helper function\n","\n","# plot results of experiment\n","plot_training_curves(train_loss, train_psnr, test_psnr)\n","plot_reconstruction(net.forward(X_test), y_test)\n","plot_reconstruction_progress(predicted_images, y_test)"],"metadata":{"id":"RVwNEfLSq_Ug"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Low Resolution Reconstruction - Optimizer of your Choice - Various Input Mapping Stategies"],"metadata":{"id":"hvD5bj__qpjr"}},{"cell_type":"code","source":["def train_wrapper(mapping, size, opt):\n","  # TODO implement\n","  # makes it easy to run all your mapping experiments in a for loop\n","  # this will similar to what you did previously in the last two sections\n","  \n","  return {\n","      'net': net, \n","      'train_psnrs': train_psnrs, \n","      'test_psnrs': test_psnrs,\n","      'train_loss': train_loss,\n","      'pred_imgs': predicted_images\n","  }\n","\n"],"metadata":{"id":"xJn8Dp8IrBYI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs = {}\n","for k in tqdm(B_dict):\n","  print(\"training\", k)\n","  outputs[k] = train_wrapper(k, size, opt)"],"metadata":{"id":"3-8E-xZFCLr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# if you did everything correctly so far, this should output a nice figure you can use in your report\n","plot_feature_mapping_comparison(outputs, y_test.reshape(size,size,3))"],"metadata":{"id":"lHshB7AvvwKC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# High Resolution Reconstruction"],"metadata":{"id":"R3Xp9T9GxmS8"}},{"cell_type":"markdown","source":["#### High Resolution Reconstruction - Optimizer of your Choice - Various Input Mapping Stategies"],"metadata":{"id":"PqiF7mqksn1M"}},{"cell_type":"markdown","source":["Repeat the previous experiment, but at the higher resolution. The reason why we have you first experiment with the lower resolution since it is faster to train and debug. Additionally, you will see how the mapping strategies perform better or worse at the two different input resolutions. "],"metadata":{"id":"wCcGOG_tstpz"}},{"cell_type":"code","source":["size = 128\n","train_data, test_data = get_image(size)"],"metadata":{"id":"aoXjcQ1Wxski"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs = {}\n","for k in tqdm(B_dict):\n","  print(\"training\", k)\n","  outputs[k] = train_wrapper(k, size,)"],"metadata":{"id":"A6xpU_WvskOh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### High Resolution Reconstruction - Image of your Choice"],"metadata":{"id":"BG2wNhrkvtFz"}},{"cell_type":"markdown","source":["When choosing an image select one that you think will give you interesting results or a better insight into the performance of different feature mappings and explain why in your report template. "],"metadata":{"id":"c8fm-X0wxY6f"}},{"cell_type":"code","source":["size = 128\n","# TODO pick an image and replace the url string\n","train_data, test_data = get_image(size, image_url=\"YOUR URL HERE\")"],"metadata":{"id":"-NLWTXXVvsZt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get input features\n","# TODO implement this by using the get_B_dict() and get_input_features() helper functions\n","\n","# run NN experiment on input features\n","# TODO implement by using the NN_experiment() helper function\n","\n","plot_training_curves(train_loss, train_psnr, test_psnr)\n","plot_reconstruction(net.forward(X_test), y_test)\n","plot_reconstruction_progress(predicted_images, y_test)"],"metadata":{"id":"y4rA4SnRwH2u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Reconstruction Process Video (Optional)\n","(For Fun!) Visualize the progress of training in a video "],"metadata":{"id":"jCE0yV-ytIu3"}},{"cell_type":"code","source":["# requires installing this additional dependency\n","!pip install imageio-ffmpeg"],"metadata":{"id":"NkDM58n_tlMe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# single video example\n","create_and_visualize_video({\"gauss\": {\"pred_imgs\": predicted_images}}, filename=\"training_high_res_gauss.mp4\")"],"metadata":{"id":"ZKA5lnTED2a5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# multi video example\n","create_and_visualize_video(outputs, epochs=1000, size=32)"],"metadata":{"id":"ucNEYrqQvXsy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"v0pYTJVg5PBL"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1BwVWCniWqdJ8uY3kEO45bDEKh4Sz33yr","timestamp":1676429175577},{"file_id":"1DAylBgQeNgfnhZZovWlZ-WTQbcBa1-OL","timestamp":1676420343251},{"file_id":"1JxUD-Tub-AyqVWKzTCQUfb2Y7VWNA7cn","timestamp":1675456427314},{"file_id":"https://github.com/tancik/fourier-feature-networks/blob/master/Demo.ipynb","timestamp":1675455979531}]},"kernelspec":{"display_name":"Python 3.9.0 ('nerf2d')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"vscode":{"interpreter":{"hash":"8ef14a750bb45c018324ac0fece7391260ac57ea293d4b9e36be86c8e7ac53c2"}},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}